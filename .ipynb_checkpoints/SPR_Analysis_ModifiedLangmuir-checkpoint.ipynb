{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import *\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### This loads in every .txt file in the specified path \n",
    "### It is slightly hardcoded for the specific data format produced by SPRAria, but should be easily\n",
    "### changeable to other formats\n",
    "def loader(adir):\n",
    "    i = 0\n",
    "    names = os.listdir(adir)\n",
    "    d = {}\n",
    "    for i in range(0,np.size(names)):\n",
    "        print(names[i])\n",
    "        if names[i][-4:] == \".txt\":\n",
    "            try:\n",
    "                d[str(names[i][:-4])] = np.loadtxt(adir+str(names[i]),skiprows=1,usecols=(0,3))\n",
    "            except IndexError:\n",
    "                print(\"Data file \"+str(names[i])+\" did not contain SPR data\")\n",
    "    #print(d)\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "ththththt\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "### This produces two plots:\n",
    "### The first is the SPR curve for the files \"conc0\", \"conc1\" up to \"conc(num)\" which you specify /\n",
    "### when calling the function, and then plots \"rinse\" at the end.\n",
    "### \"conc\" and \"rinse\" are the default names but can be passed as arguments to the function\n",
    "### The second plot is the same as the first but with the addition of splines for each concentration.\n",
    "### The equilibrium pixel valu for each concentration is then taken as the end value of each spline\n",
    "### The function then returns these pixel values for each concentraion, along with an error which is /\n",
    "### the width of the grey regions around each spline\n",
    "### The second plot is to visually confirm that the splines are reasonable. If not, you can change the /\n",
    "### value of the smoothing parameter from it's default of 10\n",
    "\n",
    "def Organise(d,num,filename=\"conc\",rinsename=\"rinse\",smoothing=10):\n",
    "    plt.figure(figsize=(14,10))\n",
    "    for i in range(0,num):\n",
    "        #print(d[filename+`i+1`][-1,0])\n",
    "        #print(d[filename+`i`][-1,0])\n",
    "        #print(np.size(d[filename+`i+1`]))\n",
    "        if np.size(d[filename+`i+1`])!=0:\n",
    "            #print(np.size(d[filename+`i+1`]))\n",
    "            for j in range(0,np.size(d[filename+`i+1`][:,0])):\n",
    "                #print(j)\n",
    "                if np.size(d[filename+`i`])!=0:\n",
    "                    d[filename+`i+1`][j][0] =d[filename+`i+1`][j][0] + d[filename+`i`][-1][0]\n",
    "                else:\n",
    "                    d[filename+`i+1`][j][0] =d[filename+`i+1`][j][0] + d[filename+`i-1`][-1][0] + 60*10\n",
    "        #print(d[filename+`i+1`][-1][0])\n",
    "    for j in range(0,np.size(d[rinsename][:,0])):\n",
    "        d[rinsename][j][0] =d[rinsename][j][0] + d[filename+str(num)][-1][0]\n",
    "    \n",
    "    d2 = {}\n",
    "    errors = np.zeros(num+1)\n",
    "    pixels = np.zeros(num+1)\n",
    "    for i in range(0,num+1):\n",
    "        #print(i)\n",
    "        if np.size(d[filename+`i`])!=0:\n",
    "            temparray = np.zeros(np.shape(d[filename+`i`]))\n",
    "            errors[i] = np.max(d[filename+`i`][-50:,1]) - np.min(d[filename+`i`][-50:,1])\n",
    "            f = UnivariateSpline(d[filename+`i`][:,0]/60, d[filename+`i`][:,1], s=smoothing)\n",
    "            temparray[:,0] = d[filename+`i`][:,0]/60\n",
    "            temparray[:,1] = f(d[filename+`i`][:,0]/60)\n",
    "            d2[filename+`i`] = temparray\n",
    "            pixels[i] = d2[filename+`i`][-1,1] - d2[filename+\"0\"][-1,1]\n",
    "        \n",
    "    return(d,d2,pixels,errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Plotter(d,d2,pixels,errors,num,filename=\"conc\",rinsename=\"rinse\",ShowFits = False):\n",
    "    plotdata1 = []\n",
    "    cmap = plt.get_cmap('jet')\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, num+2)]\n",
    "    fig1 = plt.figure(figsize=(14,10))\n",
    "    ax1 = fig1.add_subplot(1, 1, 1)\n",
    "    \n",
    "    \n",
    "    if ShowFits==False:\n",
    "        for i in range(0,num+1):\n",
    "            if np.size(d[filename+`i`])!=0:\n",
    "                plotdata1.append(ax1.plot(d[filename+`i`][:,0]/60,d[filename+`i`][:,1],label=filename+`i`,color=colors[i]))\n",
    "        plotdata1.append(ax1.plot(d[rinsename][:,0]/60,d[rinsename][:,1],label=rinsename,color=colors[num+1]))\n",
    "    else:\n",
    "         for i in range(0,num+1):\n",
    "            if np.size(d[filename+`i`])!=0:\n",
    "                plotdata1.append(ax1.plot(d[filename+`i`][:,0]/60,d[filename+`i`][:,1],label=filename+`i`,color=colors[i]))\n",
    "                plotdata1.append(ax1.plot(d2[filename+`i`][:,0],d2[filename+`i`][:,1],color='black',linewidth=3))\n",
    "                plotdata1.append(ax1.fill_between(d2[filename+`i`][:,0],d2[filename+`i`][:,1]-errors[i]/2,d2[filename+`i`][:,1]+errors[i]/2,color='gray',edgecolor='black',alpha=0.4))\n",
    "                plotdata1.append(ax1.plot(d2[filename+`i`][:,0],d2[filename+`i`][:,1],color='white',linewidth=1))\n",
    "\n",
    "    ax1.set_title(\"BTK PH Domain in 75:20:05 DOPC:DOPS:PIP3\")\n",
    "    ax1.set_ylabel(\"SPR Signal (pixels)\")\n",
    "    ax1.set_xlabel(\"Time (minutes)\")\n",
    "\n",
    "    ax1.legend(prop={'size':10})\n",
    "    #plt.show()\n",
    "    #fig1.close()\n",
    "    \n",
    "    return(ax1,plotdata1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Langmuir(concs,bmax,kd):\n",
    "    return (concs*bmax)/(concs+kd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FitToLangmuir(concs,pixels,errors):\n",
    "    popt, popv = curve_fit(Langmuir,concs,pixels,sigma=errors,bounds=(0,[1000,1000]))\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.errorbar(concs,pixels,yerr=errors/2,fmt='o')\n",
    "    c2 = np.arange(0.01,10,0.01)\n",
    "    plt.plot(c2,Langmuir(c2,*popt))\n",
    "    plt.title(\"Langmuir Binding Curve\")\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel(\"R_eq\")\n",
    "    plt.xlabel(\"Concentration (um)\")\n",
    "    string = \"bmax = \" + str(popt[0])+\" +- \"+str(np.sqrt(popv[0][0])) + \"\\n\" + \"kd = \" + str(popt[1])+\" +- \"+str(np.sqrt(popv[1][1]))\n",
    "    plt.text(0.4, 1.4, string, horizontalalignment='center',verticalalignment='center', transform=ax.transAxes,bbox=dict(facecolor='red', alpha=0.2))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"bmax = \",str(popt[0])+\" +- \"+str(np.sqrt(popv[0][0])))\n",
    "    print(\"kd = \",str(popt[1])+\" +- \"+str(np.sqrt(popv[1][1])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "2017-6-8Bilayer1-SPR.png\n",
      "conc0.txt\n",
      "Data file conc0.txt did not contain SPR data\n",
      "conc1.txt\n",
      "Data file conc1.txt did not contain SPR data\n",
      "conc10.txt\n",
      "Data file conc10.txt did not contain SPR data\n",
      "conc11.txt\n",
      "Data file conc11.txt did not contain SPR data\n",
      "conc2.txt\n",
      "Data file conc2.txt did not contain SPR data\n",
      "conc3.txt\n",
      "Data file conc3.txt did not contain SPR data\n",
      "conc4.txt\n",
      "Data file conc4.txt did not contain SPR data\n",
      "conc5.txt\n",
      "Data file conc5.txt did not contain SPR data\n",
      "conc6.txt\n",
      "Data file conc6.txt did not contain SPR data\n",
      "conc7.txt\n",
      "Data file conc7.txt did not contain SPR data\n",
      "conc8.txt\n",
      "Data file conc8.txt did not contain SPR data\n",
      "conc9.txt\n",
      "Data file conc9.txt did not contain SPR data\n",
      "CorrectedLangmuir.png\n",
      "finalrinse.txt\n",
      "Data file finalrinse.txt did not contain SPR data\n",
      "Models-Linear.png\n",
      "Models-Log.png\n",
      "NaiveLangmuir.png\n",
      "SPR_Analysis-IBBR.ipynb\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'conc1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ee0c4971aa5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrganise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrinsename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rinse\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrinsename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rinse\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mShowFits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-12a6dcef5f2c>\u001b[0m in \u001b[0;36mOrganise\u001b[0;34m(d, num, filename, rinsename, smoothing)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(d[filename+`i`][-1,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#print(np.size(d[filename+`i+1`]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;31m#print(np.size(d[filename+`i+1`]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conc1'"
     ]
    }
   ],
   "source": [
    "\n",
    "###The various concentrations have to be manually added below in micromolar (first concentation should be zero for baseline)\n",
    "concs = np.array([0,0.01,0.03,0.06,0.100,0.300,0.600,1.0,3.0,6.0,10.0,30.0])\n",
    "\n",
    "#NUMBER OF NON-ZERO CONCENTRATIONS MEASURED:\n",
    "\n",
    "num = np.size(concs) - 1\n",
    "\n",
    "#THE DIRECTORY WITH ALL THE DATA GOES HERE\n",
    "d = loader(\"../../../Downloads/IBBR/\")\n",
    "\n",
    "\n",
    "(d,d2,pixels,errors) = Organise(d,num,filename=\"conc\",rinsename=\"rinse\",smoothing=5)\n",
    "(ax,pd) = Plotter(d,d2,pixels,errors,num,filename=\"conc\",rinsename=\"rinse\",ShowFits=True)\n",
    "\n",
    "\n",
    "\n",
    "#THIS AUTOLABELS VIA THE CONCENTRATIONS\n",
    "pd[0][0].set_label(\"Baseline\")\n",
    "for i in range(1,np.size(concs)):\n",
    "    print(i)\n",
    "    if np.size(pd) == num+2:\n",
    "        pd[i][0].set_label(str(concs[i])+r' $\\mu$ mol') \n",
    "    else:\n",
    "        pd[i*4][0].set_label(str(concs[i])+r' $\\mu$ mol')\n",
    "try:\n",
    "    pd[(np.size(concs)+1)*4][0].set_label(\"Rinse\")\n",
    "except IndexError:\n",
    "    print(\"Final rinse is not plotted if ShowFits==True\")\n",
    "    \n",
    "\n",
    "ax.set_title(\"Whatever you like\")\n",
    "###    \n",
    "ax.legend()\n",
    "plt.show(ax)\n",
    "FitToLangmuir(concs,pixels,errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pixels)\n",
    "print(concs)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = np.arange(0.01,10,0.01)\n",
    "#print(con)\n",
    "plt.plot(con,(con*44.3)/(con+0.477))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
